{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2df39e",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83c41000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.smallcnn import SmallCNN\n",
    "from src.dataset import FMADataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from src.audio_processing import audio_to_mel_tensor\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e93e25",
   "metadata": {},
   "source": [
    "Maaping des genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddaa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 25: 22, 26: 23, 27: 24, 30: 25, 31: 26, 32: 27, 33: 28, 36: 29, 37: 30, 38: 31, 41: 32, 42: 33, 43: 34, 45: 35, 46: 36, 47: 37, 49: 38, 53: 39, 58: 40, 63: 41, 64: 42, 65: 43, 66: 44, 70: 45, 71: 46, 74: 47, 76: 48, 77: 49, 79: 50, 81: 51, 83: 52, 85: 53, 86: 54, 88: 55, 89: 56, 90: 57, 92: 58, 94: 59, 97: 60, 98: 61, 100: 62, 101: 63, 102: 64, 103: 65, 107: 66, 109: 67, 111: 68, 113: 69, 117: 70, 118: 71, 125: 72, 130: 73, 137: 74, 138: 75, 166: 76, 167: 77, 169: 78, 170: 79, 171: 80, 172: 81, 173: 82, 174: 83, 175: 84, 176: 85, 177: 86, 178: 87, 179: 88, 180: 89, 181: 90, 182: 91, 183: 92, 184: 93, 185: 94, 186: 95, 187: 96, 188: 97, 189: 98, 214: 99, 224: 100, 232: 101, 236: 102, 240: 103, 247: 104, 250: 105, 267: 106, 286: 107, 296: 108, 297: 109, 311: 110, 314: 111, 322: 112, 337: 113, 359: 114, 360: 115, 361: 116, 362: 117, 374: 118, 377: 119, 378: 120, 400: 121, 401: 122, 404: 123, 428: 124, 439: 125, 440: 126, 441: 127, 442: 128, 443: 129, 444: 130, 456: 131, 465: 132, 468: 133, 491: 134, 493: 135, 495: 136, 502: 137, 504: 138, 514: 139, 524: 140, 538: 141, 539: 142, 542: 143, 567: 144, 580: 145, 602: 146, 619: 147, 651: 148, 659: 149, 693: 150, 695: 151, 741: 152, 763: 153, 808: 154, 810: 155, 811: 156, 906: 157, 1032: 158, 1060: 159, 1156: 160, 1193: 161, 1235: 162}\n",
      "Nombre de classes: 163\n"
     ]
    }
   ],
   "source": [
    "genres_df = pd.read_csv(\"fma_metadata/genres.csv\")  # ton tableau avec genre_id,title,etc.\n",
    "\n",
    "genre_ids = sorted(genres_df[\"genre_id\"].tolist())\n",
    "genre_id_to_idx = {gid: i for i, gid in enumerate(genre_ids)}\n",
    "print(genre_id_to_idx)\n",
    "num_classes = len(genre_id_to_idx)\n",
    "print(f\"Nombre de classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28517695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"fma_small\"\n",
    "# file_paths = []\n",
    "\n",
    "# for dirpath, dirnames, filenames in os.walk(root):\n",
    "#     for filename in filenames:\n",
    "#         if filename.endswith(\".mp3\"):  # important\n",
    "#             full_path = os.path.join(dirpath, filename)\n",
    "#             file_paths.append(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31566122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import ast  # pour convertir les listes \"[21, 103]\" en vraies listes python\n",
    "\n",
    "tracks_df = pd.read_csv(\"fma_metadata/tracks.csv\", header=[0,1], index_col=0)\n",
    "\n",
    "genres_raw = tracks_df[(\"track\", \"genres\")]  # Series: index = track_id\n",
    "track_genre_id_map = {}                     # mapping final : track_id -> genre_id\n",
    "\n",
    "for tid, string_list in genres_raw.items():\n",
    "    try:\n",
    "        genre_ids = ast.literal_eval(string_list)  # \"[21]\" -> [21]\n",
    "        if len(genre_ids) > 0:\n",
    "            track_genre_id_map[tid] = genre_ids[0]  # premier genre_id\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "track_genre_ids = []\n",
    "\n",
    "for path in file_paths:\n",
    "    filename = os.path.basename(path)        # \"000002.mp3\"\n",
    "    track_id = int(filename.replace(\".mp3\", \"\"))  # 2\n",
    "\n",
    "    if track_id in track_genre_id_map:\n",
    "        track_genre_ids.append(track_genre_id_map[track_id])\n",
    "    else:\n",
    "        # si jamais un fichier n’a pas de genre dans tracks.csv\n",
    "        track_genre_ids.append(None)  \n",
    "\n",
    "print(len(track_genre_ids) == len(file_paths)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_genre_ids = sorted(set(track_genre_ids))\n",
    "\n",
    "# genre_id_to_idx = {gid: i for i, gid in enumerate(unique_genre_ids)}\n",
    "# idx_to_genre_id = {i: gid for gid, i in genre_id_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a54aab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_genre_ids : liste des genre_id associés à chaque fichier (par ex. [21, 21, 10, 76, ...])\n",
    "\n",
    "unique_genre_ids = sorted(set(track_genre_ids))\n",
    "genre_id_to_idx = {gid: i for i, gid in enumerate(unique_genre_ids)}\n",
    "idx_to_genre_id = {i: gid for gid, i in genre_id_to_idx.items()}\n",
    "\n",
    "num_classes = len(unique_genre_ids)\n",
    "model = SmallCNN(n_mels=128, num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "567c08ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            album                                                     \\\n",
      "         comments         date_created        date_released engineer   \n",
      "track_id                                                               \n",
      "2               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
      "3               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
      "5               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
      "10              0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN   \n",
      "20              0  2008-11-26 01:45:05  2009-01-06 00:00:00      NaN   \n",
      "\n",
      "                                                                          \\\n",
      "         favorites id                                information listens   \n",
      "track_id                                                                   \n",
      "2                4  1                                    <p></p>    6073   \n",
      "3                4  1                                    <p></p>    6073   \n",
      "5                4  1                                    <p></p>    6073   \n",
      "10               4  6                                        NaN   47632   \n",
      "20               2  4  <p> \"spiritual songs\" from Nicky Cook</p>    2710   \n",
      "\n",
      "                        ...       track                         \\\n",
      "         producer tags  ... information interest language_code   \n",
      "track_id                ...                                      \n",
      "2             NaN   []  ...         NaN     4656            en   \n",
      "3             NaN   []  ...         NaN     1470            en   \n",
      "5             NaN   []  ...         NaN     1933            en   \n",
      "10            NaN   []  ...         NaN    54881            en   \n",
      "20            NaN   []  ...         NaN      978            en   \n",
      "\n",
      "                                                                              \\\n",
      "                                                    license listens lyricist   \n",
      "track_id                                                                       \n",
      "2         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1293      NaN   \n",
      "3         Attribution-NonCommercial-ShareAlike 3.0 Inter...     514      NaN   \n",
      "5         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1151      NaN   \n",
      "10        Attribution-NonCommercial-NoDerivatives (aka M...   50135      NaN   \n",
      "20        Attribution-NonCommercial-NoDerivatives (aka M...     361      NaN   \n",
      "\n",
      "                                                 \n",
      "         number publisher tags            title  \n",
      "track_id                                         \n",
      "2             3       NaN   []             Food  \n",
      "3             4       NaN   []     Electric Ave  \n",
      "5             6       NaN   []       This World  \n",
      "10            1       NaN   []          Freeway  \n",
      "20            3       NaN   []  Spiritual Level  \n",
      "\n",
      "[5 rows x 52 columns]\n",
      "MultiIndex([( 'album',          'comments'),\n",
      "            ( 'album',      'date_created'),\n",
      "            ( 'album',     'date_released'),\n",
      "            ( 'album',          'engineer'),\n",
      "            ( 'album',         'favorites'),\n",
      "            ( 'album',                'id'),\n",
      "            ( 'album',       'information'),\n",
      "            ( 'album',           'listens'),\n",
      "            ( 'album',          'producer'),\n",
      "            ( 'album',              'tags'),\n",
      "            ( 'album',             'title'),\n",
      "            ( 'album',            'tracks'),\n",
      "            ( 'album',              'type'),\n",
      "            ('artist', 'active_year_begin'),\n",
      "            ('artist',   'active_year_end'),\n",
      "            ('artist', 'associated_labels'),\n",
      "            ('artist',               'bio'),\n",
      "            ('artist',          'comments'),\n",
      "            ('artist',      'date_created'),\n",
      "            ('artist',         'favorites'),\n",
      "            ('artist',                'id'),\n",
      "            ('artist',          'latitude'),\n",
      "            ('artist',          'location'),\n",
      "            ('artist',         'longitude'),\n",
      "            ('artist',           'members'),\n",
      "            ('artist',              'name'),\n",
      "            ('artist',  'related_projects'),\n",
      "            ('artist',              'tags'),\n",
      "            ('artist',           'website'),\n",
      "            ('artist',    'wikipedia_page'),\n",
      "            (   'set',             'split'),\n",
      "            (   'set',            'subset'),\n",
      "            ( 'track',          'bit_rate'),\n",
      "            ( 'track',          'comments'),\n",
      "            ( 'track',          'composer'),\n",
      "            ( 'track',      'date_created'),\n",
      "            ( 'track',     'date_recorded'),\n",
      "            ( 'track',          'duration'),\n",
      "            ( 'track',         'favorites'),\n",
      "            ( 'track',         'genre_top'),\n",
      "            ( 'track',            'genres'),\n",
      "            ( 'track',        'genres_all'),\n",
      "            ( 'track',       'information'),\n",
      "            ( 'track',          'interest'),\n",
      "            ( 'track',     'language_code'),\n",
      "            ( 'track',           'license'),\n",
      "            ( 'track',           'listens'),\n",
      "            ( 'track',          'lyricist'),\n",
      "            ( 'track',            'number'),\n",
      "            ( 'track',         'publisher'),\n",
      "            ( 'track',              'tags'),\n",
      "            ( 'track',             'title')],\n",
      "           )\n",
      "Index([     2,      3,      5,     10,     20,     26,     30,     46,     48,\n",
      "          134,\n",
      "       ...\n",
      "       155310, 155311, 155312, 155314, 155315, 155316, 155317, 155318, 155319,\n",
      "       155320],\n",
      "      dtype='int64', name='track_id', length=106574)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tracks_df = pd.read_csv(\"fma_metadata/tracks.csv\", header=[0,1], index_col=0)\n",
    "\n",
    "print(tracks_df.head())\n",
    "print(tracks_df.columns)\n",
    "print(tracks_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c85316a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.read_csv(\"fma_metadata/tracks.csv\", header=[0, 1], index_col=0)\n",
    "genre_top = tracks_df[(\"track\", \"genre_top\")]   # Série pandas\n",
    "# mapping : track_id (index) → genre_top (str)\n",
    "track_genre_top_map = genre_top.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "432eb78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de genres: 163\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le CSV des genres\n",
    "genres_df = pd.read_csv(\"fma_metadata/genres.csv\")  # le texte que tu as collé\n",
    "\n",
    "# liste de tous les genre_id\n",
    "genre_ids = sorted(genres_df[\"genre_id\"].tolist())\n",
    "\n",
    "# mapping pour l'entraînement\n",
    "genre_id_to_idx = {gid: i for i, gid in enumerate(genre_ids)}\n",
    "\n",
    "# mapping inverse pour interpréter les prédictions\n",
    "idx_to_genre_id = {i: gid for gid, i in genre_id_to_idx.items()}\n",
    "\n",
    "# si tu veux aussi le titre :\n",
    "genre_id_to_title = {\n",
    "    row[\"genre_id\"]: row[\"title\"]\n",
    "    for _, row in genres_df.iterrows()\n",
    "}\n",
    "\n",
    "num_classes = len(genre_ids)\n",
    "print(\"Nombre de genres:\", num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b27432e",
   "metadata": {},
   "source": [
    "Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64e4b5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remi-moustamsik/Documents/projet_lock/src/audio_processing.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(path, sr=sr, mono=True)\n",
      "[src/libmpg123/parse.c:do_readahead():1083] warning: Cannot read next header, a one-frame stream? Duh...\n",
      "/Users/remi-moustamsik/Documents/projet_lock/venv/lib/python3.12/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de chargement fma_small/133/133297.mp3: \n",
      "On ignore le fichier corrompu : fma_small/133/133297.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1776] error: part2_3_length (3360) too large for available bit count (3240)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1776] error: part2_3_length (3328) too large for available bit count (3240)\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 33361.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "/Users/remi-moustamsik/Documents/projet_lock/src/audio_processing.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(path, sr=sr, mono=True)\n",
      "/Users/remi-moustamsik/Documents/projet_lock/venv/lib/python3.12/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 22401.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 63168.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "[src/libmpg123/parse.c:do_readahead():1083] warning: Cannot read next header, a one-frame stream? Duh...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de chargement fma_small/099/099134.mp3: \n",
      "On ignore le fichier corrompu : fma_small/099/099134.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remi-moustamsik/Documents/projet_lock/src/audio_processing.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(path, sr=sr, mono=True)\n",
      "[src/libmpg123/parse.c:do_readahead():1083] warning: Cannot read next header, a one-frame stream? Duh...\n",
      "/Users/remi-moustamsik/Documents/projet_lock/venv/lib/python3.12/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de chargement fma_small/108/108925.mp3: \n",
      "On ignore le fichier corrompu : fma_small/108/108925.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1844] error: dequantization failed!\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n"
     ]
    }
   ],
   "source": [
    "root = \"fma_small\"\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".mp3\"):   # important : ignorer les autres fichiers\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "\n",
    "            # label = nom du dossier parent (ex: \"000\")\n",
    "            label = os.path.basename(dirpath)\n",
    "\n",
    "            file_paths.append(full_path)\n",
    "            labels.append(int(label))\n",
    "\n",
    "valid_paths = []\n",
    "valid_genre_ids = []\n",
    "\n",
    "for path, gid in zip(file_paths, track_genre_ids):\n",
    "    mel, sr = audio_to_mel_tensor(path)\n",
    "    if mel is None:\n",
    "        print(f\"On ignore le fichier corrompu : {path}\")\n",
    "        continue\n",
    "    valid_paths.append(path)\n",
    "    valid_genre_ids.append(gid)\n",
    "\n",
    "file_paths = valid_paths\n",
    "track_genre_ids = valid_genre_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d35916",
   "metadata": {},
   "source": [
    "Préparation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Entraînement sur GPU Apple (MPS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SmallCNN(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (conv_block3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (conv_block4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=128, out_features=163, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pour GPU classique\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Pour gpu Apple MPS\n",
    "# Permet d'être presque 10 fois plus rapide que sur CPU\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"✓ Entraînement sur GPU Apple (MPS)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ Entraînement sur CPU\")\n",
    "\n",
    "\n",
    "model = SmallCNN(n_mels=128, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f35ae",
   "metadata": {},
   "source": [
    "Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a05983ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)   # (B, 1, 128, T)\n",
    "        labels = labels.to(device)   # (B,)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits, _ = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "dataset = FMADataset(file_paths, labels, genre_id_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083531b",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "902bf84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits, probs = model(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # prédiction = classe avec probabilité max\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c666d85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 22401.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "/Users/remi-moustamsik/Documents/projet_lock/src/audio_processing.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(path, sr=sr, mono=True)\n",
      "/Users/remi-moustamsik/Documents/projet_lock/venv/lib/python3.12/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1776] error: part2_3_length (3360) too large for available bit count (3240)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 33361.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1776] error: part2_3_length (3328) too large for available bit count (3240)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 63168.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1844] error: dequantization failed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - train loss: 3.6832 | test loss: 3.6277 | test acc: 8.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 33361.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1776] error: part2_3_length (3360) too large for available bit count (3240)\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 22401.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1776] error: part2_3_length (3328) too large for available bit count (3240)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 63168.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1844] error: dequantization failed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 - train loss: 3.6136 | test loss: 3.6509 | test acc: 14.45%\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 2  # choisis le nombre d'epochs\n",
    "\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "dataset = FMADataset(file_paths, track_genre_ids, max_len=3000, genre_id_to_idx=genre_id_to_idx)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # ---- TRAIN ----\n",
    "    train_loss = train_one_epoch(\n",
    "        model=model,\n",
    "        dataloader=train_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # ---- TEST ----\n",
    "    test_loss, test_acc = evaluate(\n",
    "        model=model,\n",
    "        dataloader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{NUM_EPOCHS} \"\n",
    "        f\"- train loss: {train_loss:.4f} | test loss: {test_loss:.4f} | test acc: {test_acc*100:.2f}%\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
